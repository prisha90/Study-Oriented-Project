{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prisha90/Study-Oriented-Project-/blob/main/Glaucoma_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sV4RayeL1LVs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from skimage import measure, morphology"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DplYafZnCSHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_FOLDER = \"/content/drive/MyDrive/SOP (Rajya Laksmi Ma'am)/Work Document/G1020/Images\"\n",
        "MASK_FOLDER = \"/content/drive/MyDrive/SOP (Rajya Laksmi Ma'am)/Work Document/G1020/Masks\"\n",
        "df = pd.read_csv(\"G1020.csv\")"
      ],
      "metadata": {
        "id": "loPrvwceChTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(image):\n",
        "    \"\"\"Apply data augmentation (rotation, flipping, contrast).\"\"\"\n",
        "    angle = np.random.randint(-10, 10)\n",
        "    rotated = cv2.warpAffine(image, cv2.getRotationMatrix2D((128, 128), angle, 1), (256, 256))\n",
        "    flipped = cv2.flip(rotated, np.random.choice([-1, 0, 1]))\n",
        "    alpha = np.random.uniform(0.8, 1.2)\n",
        "    beta = np.random.randint(-30, 30)\n",
        "    return cv2.convertScaleAbs(flipped, alpha=alpha, beta=beta)\n"
      ],
      "metadata": {
        "id": "IzaLAlPPWr97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDg-GCtjACPX"
      },
      "outputs": [],
      "source": [
        "images, labels, od_masks, oc_masks = [], [], [], []\n",
        "image_size = (256, 256)\n",
        "\n",
        "print(f\"Total images in dataframe: {len(df)}\")\n",
        "\n",
        "if not os.path.exists(IMAGES_FOLDER):\n",
        "    print(f\"Error: IMAGES_FOLDER not found: {IMAGES_FOLDER}\")\n",
        "else:\n",
        "    print(f\"IMAGES_FOLDER found: {IMAGES_FOLDER}\")\n",
        "\n",
        "missing_images = [img for img in df['imageID'] if not os.path.exists(os.path.join(IMAGES_FOLDER, img))]\n",
        "if missing_images:\n",
        "    print(f\"Missing images: {len(missing_images)} images not found.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CR_f5RT6AJ0g"
      },
      "outputs": [],
      "source": [
        "for index, row in df.iterrows():\n",
        "    img_path = os.path.join(IMAGES_FOLDER, row['imageID'])\n",
        "    od_path = os.path.join(MASK_FOLDER, row['imageID'].replace(\".jpg\", \"_od.png\"))\n",
        "    oc_path = os.path.join(MASK_FOLDER, row['imageID'].replace(\".jpg\", \"_oc.png\"))\n",
        "    label = row['binaryLabels']\n",
        "\n",
        "    if os.path.exists(img_path) and os.path.exists(od_path) and os.path.exists(oc_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, image_size)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = img.reshape(image_size[0], image_size[1], 1)\n",
        "\n",
        "        od_mask = cv2.imread(od_path, cv2.IMREAD_GRAYSCALE)\n",
        "        oc_mask = cv2.imread(oc_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        images.append(augment_image(img))\n",
        "        labels.append(label)\n",
        "        od_masks.append(od_mask)\n",
        "        oc_masks.append(oc_mask)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images) / 255.0\n",
        "od_masks = np.array(od_masks) / 255.0\n",
        "oc_masks = np.array(oc_masks) / 255.0\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "SoDhRNjpabpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DU1iEvZLAR60"
      },
      "outputs": [],
      "source": [
        "X_train, X_temp, od_train, od_temp, oc_train, oc_temp, y_train, y_temp = train_test_split(\n",
        "    images, od_masks, oc_masks, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, od_val, od_test, oc_val, oc_test, y_val, y_test = train_test_split(\n",
        "    X_temp, od_temp, oc_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBo7oj_yAaBt"
      },
      "outputs": [],
      "source": [
        "# Optic disc and optic cup segmentation\n",
        "def build_unet():\n",
        "    inputs = layers.Input((256, 256, 1))\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "\n",
        "    u1 = layers.UpSampling2D((2, 2))(c3)\n",
        "    d1 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "\n",
        "    u2 = layers.UpSampling2D((2, 2))(d1)\n",
        "    d2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
        "\n",
        "    od_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='optic_disc')(d2)\n",
        "    oc_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='optic_cup')(d2)\n",
        "\n",
        "    return models.Model(inputs, [od_output, oc_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8feeA71cAfnE"
      },
      "outputs": [],
      "source": [
        "unet = build_unet()\n",
        "unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "unet.fit(X_train, [od_train, oc_train], epochs=15, batch_size=8, validation_data=(X_val, [od_val, oc_val]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "od_pred, oc_pred = unet.predict(X_test)"
      ],
      "metadata": {
        "id": "mc2PybpsXbI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ijk9xvhAgph"
      },
      "outputs": [],
      "source": [
        "def refine_mask(mask):\n",
        "    \"\"\"Apply morphological operations to clean segmentation masks.\"\"\"\n",
        "    mask = (mask > 0.5).astype(np.uint8)  # Convert to binary\n",
        "    mask = morphology.remove_small_objects(mask.astype(bool), min_size=500)\n",
        "    mask = morphology.remove_small_holes(mask.astype(bool), area_threshold=500)\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "od_refined = np.array([refine_mask(mask) for mask in od_pred])\n",
        "oc_refined = np.array([refine_mask(mask) for mask in oc_pred])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cdr(disc_mask, cup_mask):\n",
        "    disc_area = np.sum(disc_mask)\n",
        "    cup_area = np.sum(cup_mask)\n",
        "    return round((2 * cup_area) / disc_area, 4) if disc_area != 0 else 0\n",
        "\n",
        "cdr_test = np.array([calculate_cdr(od, oc) for od, oc in zip(od_pred, oc_pred)])\n",
        "\n",
        "\n",
        "def extract_isnt_quadrants(disc_mask, cup_mask):\n",
        "    \"\"\"Compute ISNT Ratio from Neuroretinal Rim (NRR).\"\"\"\n",
        "    nrr_mask = cv2.bitwise_xor(disc_mask, cup_mask)\n",
        "\n",
        "    height, width = disc_mask.shape\n",
        "    cX, cY = width // 2, height // 2\n",
        "\n",
        "    I = np.sum(nrr_mask[cY:, :])  # Inferior\n",
        "    S = np.sum(nrr_mask[:cY, :])  # Superior\n",
        "    N = np.sum(nrr_mask[:, :cX])  # Nasal\n",
        "    T = np.sum(nrr_mask[:, cX:])  # Temporal\n",
        "\n",
        "    # Compute ISNT Ratio\n",
        "    if (N + T) == 0:\n",
        "        return 0  # Avoid division by zero\n",
        "    isnt_ratio = round((1 + (I + S)) / (1 + (N + T)), 4)\n",
        "    return isnt_ratio\n",
        "\n",
        "\n",
        "def extract_blood_vessels(fundus_image):\n",
        "    \"\"\"Extract blood vessels using CLAHE and bottom-hat filtering.\"\"\"\n",
        "    # Convert to grayscale\n",
        "    green_channel = fundus_image[:, :, 1]  # Extract green channel (better contrast)\n",
        "\n",
        "    # Apply CLAHE for contrast enhancement\n",
        "    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(6,6))\n",
        "    enhanced = clahe.apply(green_channel)\n",
        "\n",
        "    # Bottom-hat filtering to extract vessels\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
        "    bottom_hat = cv2.morphologyEx(enhanced, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    # Thresholding for binary segmentation\n",
        "    threshold_value = 3.15 * np.std(bottom_hat)  # Adaptive threshold\n",
        "    _, vessel_mask = cv2.threshold(bottom_hat, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Compute ISNT quadrants for blood vessels\n",
        "    height, width = vessel_mask.shape\n",
        "    I = np.sum(vessel_mask[height//2:, :])  # Inferior\n",
        "    S = np.sum(vessel_mask[:height//2, :])  # Superior\n",
        "    N = np.sum(vessel_mask[:, :width//2])  # Nasal\n",
        "    T = np.sum(vessel_mask[:, width//2:])  # Temporal\n",
        "\n",
        "    if (N + T) == 0:\n",
        "        return 0  # Avoid division by zero\n",
        "    blood_vessel_ratio = round((1 + (I + S)) / (1 + (N + T)), 4)\n",
        "    return blood_vessel_ratio\n"
      ],
      "metadata": {
        "id": "4r2TrhdyV7Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cdr_train = np.array([calculate_cdr(od, oc) for od, oc in zip(od_pred, oc_pred)])\n",
        "isnt_train = np.array([extract_isnt_quadrants(od, oc) for od, oc in zip(od_pred, oc_pred)])\n",
        "bvr_train = np.array([extract_blood_vessels(img) for img in X_train])\n",
        "\n",
        "cdr_test = np.array([calculate_cdr(od, oc) for od, oc in zip(od_test, oc_test)])\n",
        "isnt_test = np.array([extract_isnt_quadrants(od, oc) for od, oc in zip(od_test, oc_test)])\n",
        "bvr_test = np.array([extract_blood_vessels(img) for img in X_test])\n"
      ],
      "metadata": {
        "id": "SgCoGiayb-YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_combined = np.hstack((cdr_train.reshape(-1,1), isnt_train.reshape(-1,1), bvr_train.reshape(-1,1)))\n",
        "X_test_combined = np.hstack((cdr_test.reshape(-1,1), isnt_test.reshape(-1,1), bvr_test.reshape(-1,1)))\n"
      ],
      "metadata": {
        "id": "r9Sp67zIcBMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf')\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
        "adaboost = AdaBoostClassifier(n_estimators=50)\n",
        "\n",
        "# Hyperparameter Tuning for SVM\n",
        "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
        "grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=3)\n",
        "grid_search.fit(cdr_test.reshape(-1, 1), y_test)\n",
        "\n",
        "# Train models on extracted features\n",
        "svm.fit(X_train_combined, y_train)\n",
        "mlp.fit(X_train_combined, y_train)\n",
        "adaboost.fit(X_train_combined, y_train)"
      ],
      "metadata": {
        "id": "gyUX8oqXYdZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn_WcqlpBMFM"
      },
      "outputs": [],
      "source": [
        "y_pred_svm = svm.predict(X_test_combined)\n",
        "y_pred_mlp = mlp.predict(X_test_combined)\n",
        "y_pred_adaboost = adaboost.predict(X_test_combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_agLaoycBPlo"
      },
      "outputs": [],
      "source": [
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
        "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_adaboost))\n",
        "print(\"Best SVM Parameters:\", grid_search.best_params_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}