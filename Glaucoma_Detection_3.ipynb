{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prisha90/Study-Oriented-Project/blob/main/Glaucoma_Detection_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYJFQHGDYL5q",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from skimage import morphology\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTAW4G9oYM-x"
      },
      "outputs": [],
      "source": [
        "IMAGES_FOLDER = \"/content/drive/MyDrive/SOP (Rajya Lakshmi Ma'am)/Work Document/G1020/Images\"\n",
        "MASK_FOLDER = \"/content/drive/MyDrive/SOP (Rajya Lakshmi Ma'am)/Work Document/G1020/Masks\"\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/SOP (Rajya Lakshmi Ma'am)/Work Document/G1020/G1020.csv\")\n",
        "\n",
        "df = df.sample(n=150, random_state=42)\n",
        "df = df.head(150)\n",
        "\n",
        "def load_data(df, image_size=(512, 512)):\n",
        "    images, labels, od_masks, oc_masks = [], [], [], []\n",
        "\n",
        "    print(f\"Total images in dataframe: {len(df)}\")\n",
        "\n",
        "    if not os.path.exists(IMAGES_FOLDER):\n",
        "        print(f\"Error: IMAGES_FOLDER not found: {IMAGES_FOLDER}\")\n",
        "    else:\n",
        "        print(f\"IMAGES_FOLDER found: {IMAGES_FOLDER}\")\n",
        "\n",
        "    missing_images = [img for img in df['imageID'] if not os.path.exists(os.path.join(IMAGES_FOLDER, img))]\n",
        "    if missing_images:\n",
        "        print(f\"Missing images: {len(missing_images)} images not found.\")\n",
        "\n",
        "    def rotate_image(image, angle):\n",
        "        h, w = image.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        rot_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        rotated = cv2.warpAffine(image, rot_matrix, (w, h))\n",
        "        return cv2.resize(rotated, (512, 512)).reshape(512, 512, 1)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        img_name = row['imageID']\n",
        "        label = row['binaryLabels']\n",
        "        img_path = os.path.join(IMAGES_FOLDER, img_name)\n",
        "\n",
        "        base_name = os.path.splitext(img_name)[0]\n",
        "        mask_name = f\"{base_name}.png\"\n",
        "        mask_path = os.path.join(MASK_FOLDER, mask_name)\n",
        "\n",
        "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
        "            image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, image_size)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            image = cv2.GaussianBlur(image, (65, 65), 0)\n",
        "            image = image.reshape(image_size[0], image_size[1], 1)\n",
        "\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            mask = cv2.resize(mask, image_size)\n",
        "\n",
        "            optic_disc = np.where(mask == 1, 255, 0).astype(np.uint8).reshape(image_size[0], image_size[1], 1)\n",
        "            optic_cup = np.where(mask == 2, 255, 0).astype(np.uint8).reshape(image_size[0], image_size[1], 1)\n",
        "\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "            od_masks.append(optic_disc)\n",
        "            oc_masks.append(optic_cup)\n",
        "\n",
        "            for angle in [45, 90, 170]:\n",
        "                rotated_img = rotate_image(image, angle)\n",
        "                rotated_od = rotate_image(optic_disc, angle)\n",
        "                rotated_oc = rotate_image(optic_cup, angle)\n",
        "\n",
        "                images.append(rotated_img)\n",
        "                labels.append(label)\n",
        "                od_masks.append(rotated_od)\n",
        "                oc_masks.append(rotated_oc)\n",
        "\n",
        "        else:\n",
        "            print(f\"Image not found: {img_path}\")\n",
        "\n",
        "    images = np.array(images) / 255.0\n",
        "    labels = np.array(labels)\n",
        "    od_masks = np.array(od_masks) / 255.0\n",
        "    oc_masks = np.array(oc_masks) / 255.0\n",
        "\n",
        "    print(f\"Total images after augmentation: {len(images)}\")\n",
        "    print(f\"Total labels: {len(labels)}\")\n",
        "    print(f\"Total OD masks: {len(od_masks)}\")\n",
        "    print(f\"Total OC masks: {len(oc_masks)}\")\n",
        "\n",
        "    return images, labels, od_masks, oc_masks\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9a-WSr9YbaG"
      },
      "outputs": [],
      "source": [
        "images, labels, od_masks, oc_masks = load_data(df)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp, od_train, od_temp, oc_train, oc_temp = train_test_split(\n",
        "    images, labels, od_masks, oc_masks, test_size=0.3, random_state=42)\n",
        "\n",
        "X_val, X_test, y_val, y_test, od_val, od_test, oc_val, oc_test = train_test_split(\n",
        "    X_temp, y_temp, od_temp, oc_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHwZ4Ci4YWPy"
      },
      "outputs": [],
      "source": [
        "def build_unet():\n",
        "    inputs = layers.Input((512, 512, 1))\n",
        "\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    c4 = Dropout(0.5)(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = Dropout(0.5)(c5)\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    u6 = UpSampling2D((2, 2))(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    od_outputs = Conv2D(1, (1, 1), activation='sigmoid', name='od_output')(c9)\n",
        "    oc_outputs = Conv2D(1, (1, 1), activation='sigmoid', name='oc_output')(c9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=[od_outputs, oc_outputs])\n",
        "    return model\n",
        "\n",
        "unet = build_unet()\n",
        "unet.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.0004, momentum=0.95),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[['accuracy'],['accuracy']]\n",
        ")\n",
        "\n",
        "unet.fit(X_train, [od_train, oc_train], epochs=5, batch_size=2,\n",
        "         validation_data=(X_val, [od_val, oc_val]))\n",
        "\n",
        "od_pred, oc_pred = unet.predict(X_test)\n",
        "\n",
        "print(\"Prediction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQOhIYs2Yiir"
      },
      "outputs": [],
      "source": [
        "def calculate_cdr(disc_mask, cup_mask):\n",
        "    disc_area = np.sum(disc_mask)\n",
        "    cup_area = np.sum(cup_mask)\n",
        "    disc_mask = (disc_mask > 0).astype(np.uint8)\n",
        "    cup_mask = (cup_mask > 0).astype(np.uint8)\n",
        "\n",
        "\n",
        "    return round((2 * cup_area) / disc_area, 4) if disc_area != 0 else 0\n",
        "\n",
        "def extract_isnt_quadrants(disc_mask, cup_mask):\n",
        "    disc_mask = disc_mask.squeeze()\n",
        "    cup_mask = cup_mask.squeeze()\n",
        "\n",
        "    disc_mask_rotated = np.rot90(disc_mask)\n",
        "    cup_mask_rotated = np.rot90(cup_mask)\n",
        "\n",
        "    nrr_mask = cv2.bitwise_xor(disc_mask_rotated, cup_mask_rotated)\n",
        "\n",
        "    height, width = disc_mask.shape\n",
        "    I = np.sum(nrr_mask[height//2:, :])\n",
        "    S = np.sum(nrr_mask[:height//2, :])\n",
        "    N = np.sum(nrr_mask[:, :width//2])\n",
        "    T = np.sum(nrr_mask[:, width//2:])\n",
        "\n",
        "    return round((1 + (I + S)) / (1 + (N + T)), 4) if (N + T) != 0 else 0\n",
        "\n",
        "def extract_blood_vessels(fundus_image):\n",
        "    if len(fundus_image.shape) == 2 or fundus_image.shape[2] == 1:\n",
        "        green_channel = fundus_image[:, :, 0].astype(np.uint8)  # Use the only available channel\n",
        "    else:\n",
        "        green_channel = fundus_image[:, :, 1].astype(np.uint8)\n",
        "    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(6,6))\n",
        "    enhanced = clahe.apply(green_channel)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
        "    bottom_hat = cv2.morphologyEx(enhanced, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    threshold_value = max(10, 3.15 * np.std(bottom_hat))\n",
        "    _, vessel_mask = cv2.threshold(bottom_hat, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    height, width = vessel_mask.shape\n",
        "    I = np.sum(vessel_mask[height//2:, :])\n",
        "    S = np.sum(vessel_mask[:height//2, :])\n",
        "    N = np.sum(vessel_mask[:, :width//2])\n",
        "    T = np.sum(vessel_mask[:, width//2:])\n",
        "\n",
        "    return round((1 + (I + S)) / (1 + (N + T)), 4) if (N + T) != 0 else 0\n",
        "\n",
        "cdr_train = np.array([calculate_cdr(od, oc) for od, oc in zip(od_train, oc_train)])\n",
        "isnt_train = np.array([extract_isnt_quadrants(od, oc) for od, oc in zip(od_train, oc_train)])\n",
        "bvr_train = np.array([extract_blood_vessels(img) for img in X_train])\n",
        "\n",
        "X_train_combined = np.hstack((cdr_train.reshape(-1,1), isnt_train.reshape(-1,1), bvr_train.reshape(-1,1)))\n",
        "\n",
        "cdr_test = np.array([calculate_cdr(od, oc) for od, oc in zip(od_test, oc_test)])\n",
        "isnt_test = np.array([extract_isnt_quadrants(od, oc) for od, oc in zip(od_test, oc_test)])\n",
        "bvr_test = np.array([extract_blood_vessels(img) for img in X_test])\n",
        "\n",
        "X_test_combined = np.hstack((cdr_test.reshape(-1,1), isnt_test.reshape(-1,1), bvr_test.reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SSj2v2QYu8b"
      },
      "outputs": [],
      "source": [
        "print(f\"X_train_combined shape: {X_train_combined.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test_combined shape: {X_test_combined.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gUhsfifYzfw"
      },
      "outputs": [],
      "source": [
        "svm = SVC(C=10, gamma=1, kernel='rbf', probability=True)\n",
        "svm.fit(X_train_combined, y_train)\n",
        "svm_predictions = svm.predict(X_test_combined)\n",
        "\n",
        "mlp = Sequential([\n",
        "    Dense(3, activation=relu, input_shape=(X_train_combined.shape[1],)),\n",
        "    Dense(2, activation=relu),\n",
        "    Dense(1, activation=sigmoid)\n",
        "])\n",
        "mlp.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "mlp_model.fit(X_train_combined, y_train, epochs=120, batch_size=2, verbose=1)\n",
        "mlp_predictions = mlp.predict(X_test_combined)\n",
        "\n",
        "adaboost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3), n_estimators=100)\n",
        "\n",
        "adaboost = AdaBoostClassifier(n_estimators=50, random_state=20)\n",
        "adaboost.fit(X_train_combined, y_train)\n",
        "adaboost_predictions = adaboost.predict(X_test_combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07Oe5wyvY5ri"
      },
      "outputs": [],
      "source": [
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "mlp_accuracy = accuracy_score(y_test, mlp_predictions)\n",
        "adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)\n",
        "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
        "print(f\"MLP Accuracy: {mlp_accuracy}\")\n",
        "print(f\"AdaBoost Accuracy: {adaboost_accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}