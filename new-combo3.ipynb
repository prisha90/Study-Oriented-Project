{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2716645,"sourceType":"datasetVersion","datasetId":1655371},{"sourceId":3863247,"sourceType":"datasetVersion","datasetId":2296461},{"sourceId":144899194,"sourceType":"kernelVersion"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import cv2\n# import os\n# from sklearn.svm import SVC\n# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n# from sklearn.model_selection import train_test_split\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n# from sklearn.linear_model import LogisticRegression\n# from tensorflow.keras.applications import ResNet50\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n# from tensorflow.keras.applications import EfficientNetB0\n# from imblearn.over_sampling import RandomOverSampler\n# from imblearn.over_sampling import SMOTE\n\n# IMG_SIZE = (224, 224)  \n# BATCH_SIZE = 32\n# RANDOM_STATE = 42\n\n# IMAGES_FOLDER = \"/kaggle/input/glaucoma-datasets/G1020/Images\"\n# df = pd.read_csv(\"/kaggle/input/glaucoma-datasets/G1020/G1020.csv\")\n\n# def load_data(df, IMG_SIZE):\n#     images = []\n#     labels = []\n    \n#     for _, row in df.iterrows():\n#         img_name = row['imageID']\n#         label = row['binaryLabels']\n#         img_path = os.path.join(IMAGES_FOLDER, img_name)\n#         if os.path.exists(img_path):\n#             img = cv2.imread(img_path)\n#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#             img = cv2.resize(img, IMG_SIZE)\n#             images.append(img)\n#             labels.append(row['binaryLabels'])\n    \n#     return np.array(images), np.array(labels)\n\n# images, labels = load_data(df, IMG_SIZE)\n# images = images.astype('float32') / 255.0\n\n# X_train, X_test, y_train, y_test = train_test_split(\n#     images, labels, test_size=0.2, stratify=labels, random_state=RANDOM_STATE\n# )\n\n# datagen = ImageDataGenerator(\n#     rotation_range=30,\n#     brightness_range=[0.6, 1.4], \n#     zoom_range=0.3,\n#     horizontal_flip=True\n# )\n\n\n# augmented_images = []\n# augmented_labels = []\n# for x, y in zip(X_train, y_train):\n#     for _ in range(3):  \n#         augmented_images.append(datagen.random_transform(x))\n#         augmented_labels.append(y)\n        \n# X_train_aug = np.concatenate([X_train, np.array(augmented_images, dtype=np.float32)])\n# y_train_aug = np.concatenate([y_train, np.array(augmented_labels)])\n\n\n# # Feature extraction with ResNet50\n# def extract_features(images):\n#     # base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n#     # x = GlobalAveragePooling2D()(base_model.output)\n#     # x = Dense(1024, activation='relu')(x)  \n#     # x = Dense(512, activation='relu')(x)  \n#     # x = Dropout(0.3)(x)\n#     # feature_extractor = Model(inputs=base_model.input, outputs=x)\n\n#     base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(*IMG_SIZE, 3))\n#     x = GlobalAveragePooling2D()(base_model.output)\n#     x = Dense(1024, activation='relu')(x)\n#     x = Dropout(0.3)(x)\n#     feature_extractor = Model(inputs=base_model.input, outputs=x)\n    \n#     features = feature_extractor.predict(images, batch_size=BATCH_SIZE, verbose=1)\n#     return features\n\n\n# print(\"Extracting training features...\")\n# train_features = extract_features(X_train)\n\n# print(\"Extracting test features...\")\n# test_features = extract_features(X_test)\n\n# # Normalize features\n# # scaler = StandardScaler()\n# scaler = MinMaxScaler()\n# train_features_aug = extract_features(X_train_aug)\n# X_train_features_aug = scaler.fit_transform(train_features_aug)\n# X_test_features = scaler.transform(test_features)\n\n# smote = SMOTE(random_state=RANDOM_STATE)\n# X_train_sm, y_train_sm = smote.fit_resample(X_train_features_aug, y_train_aug)\n# ros = RandomOverSampler(random_state=RANDOM_STATE)\n# X_train_bal, y_train_bal = ros.fit_resample(X_train_features_aug, y_train_aug)\n\n# # svm_params = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1], 'kernel': ['rbf']}\n# # svm_grid = GridSearchCV(SVC(probability=True), svm_params, cv=5, n_jobs=-1, verbose=2)\n# # svm_grid.fit(X_train_bal, y_train_bal)\n# # print(f\"Best SVM parameters: {svm_grid.best_params_}\")\n# # y_pred = svm_grid.predict(X_test_features)\n# # y_prob = svm_grid.predict_proba(X_test_features)[:, 1]\n\n# svm = SVC(probability=True, class_weight={0: 1, 1: 3}, C=10, gamma=1, kernel='rbf')\n# svm.fit(X_train_bal, y_train_bal)\n# y_pred = svm.predict(X_test_features)\n# y_prob = svm.predict_proba(X_test_features)[:, 1]\n\n# rf = RandomForestClassifier(n_estimators=300, max_depth=20, class_weight={0: 1, 1: 3}, random_state=RANDOM_STATE)\n# rf.fit(X_train_bal, y_train_bal)\n# y_pred_rf = rf.predict(X_test_features)\n# y_prob_rf = rf.predict_proba(X_test_features)[:, 1]\n\n# cnn_model = Sequential([\n#     Conv2D(32, (3,3), activation='relu', input_shape=(*IMG_SIZE, 3)),\n#     MaxPooling2D(2,2),\n#     Conv2D(64, (3,3), activation='relu'),\n#     MaxPooling2D(2,2),\n#     Flatten(),\n#     Dense(512, activation='relu'),\n#     Dropout(0.5),\n#     Dense(1, activation='sigmoid')\n# ])\n\n# cnn_model.compile(optimizer='adam', loss=focal_loss(), metrics=['accuracy'])\n# cnn_model.fit(X_train_bal, y_train_bal, epochs=10, batch_size=32)\n\n# y_pred_cnn = cnn.predict(X_test_features)\n# y_prob_cnn = cnn.predict_proba(X_test_features)[:, 1]\n\n# print(\"\\nClassification Report (SVM):\")\n# print(classification_report(y_test, y_pred, target_names=[\"Normal\", \"Glaucoma\"]))\n# print(f\"\\nSVM Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n# print(f\"SVM AUC-ROC: {roc_auc_score(y_test, y_prob):.4f}\")\n\n# logreg = LogisticRegression(max_iter=1000)\n# logreg.fit(X_train_features_aug, y_train_aug)\n# y_pred_logreg = logreg.predict(X_test_features)\n# print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, y_pred_logreg):.4f}\")\n\n# print(\"\\nClassification Report (Random Forest):\")\n# print(classification_report(y_test, y_pred_rf, target_names=[\"Normal\", \"Glaucoma\"]))\n# print(f\"\\nRandom Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n# print(f\"Random Forest AUC-ROC: {roc_auc_score(y_test, y_prob_rf):.4f}\")\n\n# print(\"\\nClassification Report (CNN):\")\n# print(classification_report(y_test, y_pred_cnn, target_names=[\"Normal\", \"Glaucoma\"]))\n# print(f\"\\nCNN Accuracy: {accuracy_score(y_test, y_pred_cnn):.4f}\")\n# print(f\"CNN AUC-ROC: {roc_auc_score(y_test, y_prob_cnn):.4f}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-09T01:10:15.939244Z","iopub.execute_input":"2025-04-09T01:10:15.939604Z","iopub.status.idle":"2025-04-09T01:10:15.945973Z","shell.execute_reply.started":"2025-04-09T01:10:15.939578Z","shell.execute_reply":"2025-04-09T01:10:15.944759Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten, Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import make_pipeline\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\n\n# Constants\nIMG_SIZE = (224, 224)  \nBATCH_SIZE = 32\nRANDOM_STATE = 42\nEPOCHS = 50\n\n# Paths\nIMAGES_FOLDER = \"/kaggle/input/glaucoma-datasets/G1020/Images\"\ndf = pd.read_csv(\"/kaggle/input/glaucoma-datasets/G1020/G1020.csv\")\n\n# Improved F1 metric\ndef f1_metric(y_true, y_pred):\n    y_true = K.cast(y_true, 'float32')\n    y_pred = K.cast(K.round(y_pred), 'float32')\n    \n    tp = K.sum(y_true * y_pred)\n    fp = K.sum((1 - y_true) * y_pred)\n    fn = K.sum(y_true * (1 - y_pred))\n\n    precision = tp / (tp + fp + K.epsilon())\n    recall = tp / (tp + fn + K.epsilon())\n\n    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n    return f1\n\n# Enhanced data loading with CLAHE and normalization\ndef load_data(df, IMG_SIZE):\n    images = []\n    labels = []\n    \n    for _, row in df.iterrows():\n        img_name = row['imageID']\n        label = row['binaryLabels']\n        img_path = os.path.join(IMAGES_FOLDER, img_name)\n        if os.path.exists(img_path):\n            img = cv2.imread(img_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, IMG_SIZE)\n            \n            # Enhanced preprocessing\n            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n            l, a, b = cv2.split(lab)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n            cl = clahe.apply(l)\n            limg = cv2.merge((cl,a,b))\n            img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n            \n            # Normalize per image\n            img = (img - img.min()) / (img.max() - img.min())\n            \n            images.append(img)\n            labels.append(label)\n    \n    return np.array(images), np.array(labels)\n\n# Load and preprocess data\nimages, labels = load_data(df, IMG_SIZE)\nimages = images.astype('float32')\nlabels = labels.astype('float32')\n\n# Split data with stratification\nX_train, X_test, y_train, y_test = train_test_split(\n    images, labels, test_size=0.15, stratify=labels, random_state=RANDOM_STATE\n)\n\n# Enhanced augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    brightness_range=[0.8, 1.2],\n    fill_mode='reflect'\n)\n\n# Feature extraction with EfficientNetB0\ndef extract_features(images):\n    base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(*IMG_SIZE, 3))\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(1024, activation='relu', kernel_regularizer=l2(1e-4))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    feature_extractor = Model(inputs=base_model.input, outputs=x)\n    \n    features = feature_extractor.predict(images, batch_size=BATCH_SIZE, verbose=1)\n    return features\n\nprint(\"Extracting training features...\")\ntrain_features = extract_features(X_train)\nprint(\"Extracting test features...\")\ntest_features = extract_features(X_test)\n\n# Normalize features\nscaler = StandardScaler()\nX_train_features = scaler.fit_transform(train_features)\nX_test_features = scaler.transform(test_features)\n\n# Improved class balancing\nsampler = make_pipeline(\n    SMOTE(sampling_strategy=0.8, random_state=RANDOM_STATE),\n    RandomUnderSampler(sampling_strategy=0.9, random_state=RANDOM_STATE)\n)\nX_train_bal, y_train_bal = sampler.fit_resample(X_train_features, y_train)\n\n# Enhanced ensemble model\nestimators = [\n    ('rf', RandomForestClassifier(n_estimators=500, max_depth=20, \n                                class_weight='balanced', random_state=RANDOM_STATE)),\n    ('svm', SVC(C=1, gamma='scale', kernel='rbf', \n               probability=True, class_weight='balanced', random_state=RANDOM_STATE)),\n    ('gb', GradientBoostingClassifier(n_estimators=300, learning_rate=0.05,\n                                    max_depth=7, random_state=RANDOM_STATE))\n]\n\nstack = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(class_weight='balanced', C=0.1, penalty='l2', max_iter=1000),\n    cv=5,\n    n_jobs=-1\n)\n\nstack.fit(X_train_bal, y_train_bal)\ny_pred_stack = stack.predict(X_test_features)\ny_prob_stack = stack.predict_proba(X_test_features)[:, 1]\n\n# Enhanced CNN Model\ndef create_cnn_model():\n    inputs = Input(shape=(*IMG_SIZE, 3))\n    \n    # Feature extraction\n    x = Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(2,2)(x)\n    x = Dropout(0.2)(x)\n    \n    x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(2,2)(x)\n    x = Dropout(0.3)(x)\n    \n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(2,2)(x)\n    x = Dropout(0.4)(x)\n    \n    # Classification head\n    x = Flatten()(x)\n    x = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    \n    model.compile(\n        optimizer=Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['accuracy', f1_metric]\n    )\n    return model\n\n# Enhanced callbacks\ncallbacks = [\n    EarlyStopping(patience=15, restore_best_weights=True, monitor='val_f1_metric', mode='max'),\n    ReduceLROnPlateau(factor=0.2, patience=7, monitor='val_f1_metric', mode='max', min_lr=1e-6),\n    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_f1_metric', mode='max')\n]\n\n# Data generators for CNN\ntrain_generator = train_datagen.flow(\n    X_train, y_train,\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n\ncnn_model = create_cnn_model()\nhistory = cnn_model.fit(\n    train_generator,\n    steps_per_epoch=len(X_train) // BATCH_SIZE,\n    validation_data=(X_test, y_test),\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    class_weight={0:1, 1:3}  # Higher weight for glaucoma cases\n)\n\n# Evaluate models\nprint(\"\\n=== Enhanced Ensemble Model (Stacking) ===\")\nprint(classification_report(y_test, y_pred_stack, target_names=[\"Normal\", \"Glaucoma\"]))\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_stack):.4f}\")\nprint(f\"AUC-ROC: {roc_auc_score(y_test, y_prob_stack):.4f}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred_stack, average='weighted'):.4f}\")\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred_stack))\n\n# CNN evaluation\ny_pred_cnn = (cnn_model.predict(X_test) > 0.5).astype(int)\ny_prob_cnn = cnn_model.predict(X_test)\nprint(\"\\n=== Enhanced CNN Model ===\")\nprint(classification_report(y_test, y_pred_cnn, target_names=[\"Normal\", \"Glaucoma\"]))\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_cnn):.4f}\")\nprint(f\"AUC-ROC: {roc_auc_score(y_test, y_prob_cnn):.4f}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred_cnn, average='weighted'):.4f}\")\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred_cnn))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T01:10:16.130476Z","iopub.execute_input":"2025-04-09T01:10:16.130826Z","iopub.status.idle":"2025-04-09T01:13:18.260939Z","shell.execute_reply.started":"2025-04-09T01:10:16.130797Z","shell.execute_reply":"2025-04-09T01:13:18.259092Z"}},"outputs":[{"name":"stdout","text":"Extracting training features...\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step\nExtracting test features...\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-f8e1d180d322>\u001b[0m in \u001b[0;36m<cell line: 149>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_bal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_bal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0my_pred_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0my_prob_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0my_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# base estimators will be used in transform, predict, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# predict_proba. They are exposed publicly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fit_single_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix, f1_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\n# Constants\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 8\nRANDOM_STATE = 42\nEPOCHS = 50\n\n# Custom F1 metric\ndef f1_metric(y_true, y_pred):\n    y_true = K.cast(y_true, 'float32')\n    y_pred = K.cast(K.round(y_pred), 'float32')\n    tp = K.sum(y_true * y_pred)\n    fp = K.sum((1 - y_true) * y_pred)\n    fn = K.sum(y_true * (1 - y_pred))\n    precision = tp / (tp + fp + K.epsilon())\n    recall = tp / (tp + fn + K.epsilon())\n    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n    return f1\n\ndef load_images_from_folders(base_path):\n    images = []\n    labels = []\n    \n    class_mapping = {'normal': 0, 'glaucoma': 1}\n    found_folders = {}\n\n    # Walk recursively to find class folders\n    for root, dirs, files in os.walk(base_path):\n        for folder in dirs:\n            folder_lower = folder.lower()\n            if folder_lower in class_mapping:\n                full_path = os.path.join(root, folder)\n                found_folders[full_path] = class_mapping[folder_lower]\n\n    if not found_folders:\n        raise ValueError(f\"No valid class folders ('normal', 'glaucoma') found in {base_path}\")\n\n    print(f\"Found class folders: {list(found_folders.keys())}\")\n\n    for class_path, class_label in found_folders.items():\n        for fname in os.listdir(class_path):\n            if fname.lower().endswith(('.jpg', '.png', '.jpeg')):\n                path = os.path.join(class_path, fname)\n                try:\n                    img = cv2.imread(path)\n                    if img is None:\n                        print(f\"Warning: Could not read image {path}\")\n                        continue\n                        \n                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                    img = cv2.resize(img, IMG_SIZE)\n\n                    # Enhanced preprocessing\n                    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n                    l, a, b = cv2.split(lab)\n                    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n                    cl = clahe.apply(l)\n                    limg = cv2.merge((cl, a, b))\n                    img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n\n                    # Normalize and enhance contrast\n                    img = img.astype('float32') / 255.0\n                    img = (img - img.mean()) / (img.std() + 1e-7)\n\n                    images.append(img)\n                    labels.append(class_label)\n                except Exception as e:\n                    print(f\"Error processing {path}: {str(e)}\")\n                    continue\n    \n    if len(images) == 0:\n        raise ValueError(f\"No valid images found in {base_path}\")\n    \n    return np.array(images), np.array(labels)\n\n# Define paths based on your structure\ntrain_path = \"/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Training-20211018T055246Z-001/Training\"\ntest_path = \"/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Test-20211018T060000Z-001/Test\"\n\n# Load data with enhanced error handling\ntry:\n    X_train, y_train = load_images_from_folders(train_path)\n    X_test, y_test = load_images_from_folders(test_path)\n    print(f\"Loaded {len(X_train)} training images and {len(X_test)} test images\")\n    print(\"Training class distribution:\", np.unique(y_train, return_counts=True))\n    print(\"Test class distribution:\", np.unique(y_test, return_counts=True))\n    \n    # Check if we have at least 2 classes\n    if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n        raise ValueError(\"Dataset must contain both normal and glaucoma cases for classification\")\n        \nexcept Exception as e:\n    print(f\"\\nError loading data: {str(e)}\")\n    print(\"\\nDirectory structure:\")\n    for root, dirs, files in os.walk(\"/kaggle/input\"):\n        print(root)\n    raise\n\n# Data augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='reflect'\n)\n\n# Feature extraction with EfficientNetB0\ndef extract_features(images):\n    base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(*IMG_SIZE, 3))\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    feature_model = Model(inputs=base_model.input, outputs=x)\n    return feature_model.predict(images, batch_size=BATCH_SIZE, verbose=1)\n\n# Extract features\nprint(\"\\nExtracting training features...\")\ntrain_features = extract_features(X_train)\nprint(\"Extracting test features...\")\ntest_features = extract_features(X_test)\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(train_features)\nX_test_scaled = scaler.transform(test_features)\n\n# CNN Model\ndef create_cnn_model():\n    model = Sequential([\n        Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(*IMG_SIZE, 3)),\n        BatchNormalization(),\n        MaxPooling2D(2,2),\n        Dropout(0.2),\n        \n        Conv2D(64, (3,3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPooling2D(2,2),\n        Dropout(0.3),\n        \n        Conv2D(128, (3,3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPooling2D(2,2),\n        Dropout(0.4),\n        \n        Flatten(),\n        Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    model.compile(\n        optimizer=Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['accuracy', f1_metric]\n    )\n    return model\n\n# Callbacks\ncallbacks = [\n    EarlyStopping(patience=15, restore_best_weights=True, monitor='val_f1_metric', mode='max'),\n    ReduceLROnPlateau(factor=0.2, patience=7, monitor='val_f1_metric', mode='max', min_lr=1e-6),\n    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_f1_metric', mode='max')\n]\n\n# Train CNN\nprint(\"\\nTraining CNN model...\")\ncnn_model = create_cnn_model()\nhistory = cnn_model.fit(\n    train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n    steps_per_epoch=len(X_train) // BATCH_SIZE,\n    validation_data=(X_test, y_test),\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    class_weight={0:1, 1:2}  # Adjust weights based on class imbalance\n)\n\n# Evaluate CNN\ny_pred_cnn = (cnn_model.predict(X_test) > 0.5).astype(int)\ny_prob_cnn = cnn_model.predict(X_test)\nprint(\"\\n=== CNN Model Results ===\")\nprint(classification_report(y_test, y_pred_cnn, target_names=[\"Normal\", \"Glaucoma\"]))\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_cnn):.4f}\")\nprint(f\"AUC: {roc_auc_score(y_test, y_prob_cnn):.4f}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred_cnn, average='weighted'):.4f}\")\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred_cnn))\n\n# Traditional ML models\nprint(\"\\nTraining traditional ML models...\")\nmodels = {\n    'Random Forest': RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE),\n    'SVM': SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=RANDOM_STATE),\n    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE)\n}\n\nfor name, model in models.items():\n    model.fit(X_train_scaled, y_train)\n    y_pred = model.predict(X_test_scaled)\n    y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, \"predict_proba\") else None\n    \n    print(f\"\\n=== {name} Results ===\")\n    print(classification_report(y_test, y_pred, target_names=[\"Normal\", \"Glaucoma\"]))\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    if y_prob is not None:\n        print(f\"AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n    print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T02:41:26.098824Z","iopub.execute_input":"2025-04-09T02:41:26.099229Z","iopub.status.idle":"2025-04-09T02:42:28.332930Z","shell.execute_reply.started":"2025-04-09T02:41:26.099193Z","shell.execute_reply":"2025-04-09T02:42:28.331864Z"}},"outputs":[{"name":"stdout","text":"Found class folders: ['/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Training-20211018T055246Z-001/Training/Images/GLAUCOMA', '/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Training-20211018T055246Z-001/Training/Images/NORMAL']\nFound class folders: ['/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Test-20211018T060000Z-001/Test/Images/glaucoma', '/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Test-20211018T060000Z-001/Test/Images/normal']\nLoaded 50 training images and 51 test images\nTraining class distribution: (array([0, 1]), array([18, 32]))\nTest class distribution: (array([0, 1]), array([13, 38]))\n\nExtracting training features...\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 842ms/step\nExtracting test features...\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 881ms/step\n\nTraining CNN model...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.5922 - f1_metric: 0.5842 - loss: 6.7666 - val_accuracy: 0.2549 - val_f1_metric: 0.0000e+00 - val_loss: 5.8848 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - f1_metric: 0.6250 - loss: 7.9237","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.5000 - f1_metric: 0.6250 - loss: 7.9237 - val_accuracy: 0.3529 - val_f1_metric: 0.1351 - val_loss: 5.8081 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 410ms/step - accuracy: 0.4919 - f1_metric: 0.5806 - loss: 7.0440 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 5.5452 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - f1_metric: 0.5556 - loss: 6.4317 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 5.5529 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6830 - f1_metric: 0.6015 - loss: 6.3913 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 5.7124 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - f1_metric: 0.6667 - loss: 8.5306 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 5.7472 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6917 - f1_metric: 0.4422 - loss: 5.8758 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 5.9850 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - f1_metric: 0.5000 - loss: 7.2764 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 6.0411 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5131 - f1_metric: 0.4572 - loss: 6.7364 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 6.3103 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7500 - f1_metric: 0.6000 - loss: 6.0024 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 6.3543 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4842 - f1_metric: 0.4708 - loss: 6.7089 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 6.5864 - learning_rate: 2.0000e-05\nEpoch 12/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6250 - f1_metric: 0.3000 - loss: 7.2265 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 6.6175 - learning_rate: 2.0000e-05\nEpoch 13/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6336 - f1_metric: 0.5029 - loss: 6.2883 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 6.8481 - learning_rate: 2.0000e-05\nEpoch 14/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7500 - f1_metric: 0.6000 - loss: 5.7223 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 6.8792 - learning_rate: 2.0000e-05\nEpoch 15/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6188 - f1_metric: 0.5512 - loss: 6.0604 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 7.0727 - learning_rate: 2.0000e-05\nEpoch 16/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8750 - f1_metric: 0.5556 - loss: 5.3283 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 7.1059 - learning_rate: 2.0000e-05\nEpoch 17/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6562 - f1_metric: 0.5080 - loss: 5.8198 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 7.2922 - learning_rate: 2.0000e-05\nEpoch 18/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3750 - f1_metric: 0.5000 - loss: 7.2939 - val_accuracy: 0.7451 - val_f1_metric: 0.7400 - val_loss: 7.3223 - learning_rate: 4.0000e-06\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n\n=== CNN Model Results ===\n              precision    recall  f1-score   support\n\n      Normal       0.00      0.00      0.00        13\n    Glaucoma       0.75      1.00      0.85        38\n\n    accuracy                           0.75        51\n   macro avg       0.37      0.50      0.43        51\nweighted avg       0.56      0.75      0.64        51\n\nAccuracy: 0.7451\nAUC: 0.6154\nF1 Score: 0.6363\nConfusion Matrix:\n[[ 0 13]\n [ 0 38]]\n\nTraining traditional ML models...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\n=== Random Forest Results ===\n              precision    recall  f1-score   support\n\n      Normal       0.00      0.00      0.00        13\n    Glaucoma       0.75      1.00      0.85        38\n\n    accuracy                           0.75        51\n   macro avg       0.37      0.50      0.43        51\nweighted avg       0.56      0.75      0.64        51\n\nAccuracy: 0.7451\nAUC: 0.5182\nF1 Score: 0.6363\nConfusion Matrix:\n[[ 0 13]\n [ 0 38]]\n\n=== SVM Results ===\n              precision    recall  f1-score   support\n\n      Normal       0.00      0.00      0.00        13\n    Glaucoma       0.75      1.00      0.85        38\n\n    accuracy                           0.75        51\n   macro avg       0.37      0.50      0.43        51\nweighted avg       0.56      0.75      0.64        51\n\nAccuracy: 0.7451\nAUC: 0.5000\nF1 Score: 0.6363\nConfusion Matrix:\n[[ 0 13]\n [ 0 38]]\n\n=== Logistic Regression Results ===\n              precision    recall  f1-score   support\n\n      Normal       0.00      0.00      0.00        13\n    Glaucoma       0.75      1.00      0.85        38\n\n    accuracy                           0.75        51\n   macro avg       0.37      0.50      0.43        51\nweighted avg       0.56      0.75      0.64        51\n\nAccuracy: 0.7451\nAUC: 0.5000\nF1 Score: 0.6363\nConfusion Matrix:\n[[ 0 13]\n [ 0 38]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":42}]}