{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d74ca6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-02T01:14:49.753743Z",
     "iopub.status.busy": "2025-04-02T01:14:49.753466Z",
     "iopub.status.idle": "2025-04-02T01:15:03.658717Z",
     "shell.execute_reply": "2025-04-02T01:15:03.656972Z"
    },
    "papermill": {
     "duration": 13.909637,
     "end_time": "2025-04-02T01:15:03.660278",
     "exception": false,
     "start_time": "2025-04-02T01:14:49.750641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             imageID  binaryLabels\n",
      "0        image_0.jpg             0\n",
      "1        image_1.jpg             0\n",
      "2        image_3.jpg             0\n",
      "3        image_4.jpg             0\n",
      "4        image_5.jpg             0\n",
      "...              ...           ...\n",
      "1015  image_3198.jpg             0\n",
      "1016  image_3199.jpg             0\n",
      "1017  image_3201.jpg             1\n",
      "1018  image_3202.jpg             1\n",
      "1019  image_2568.jpg             0\n",
      "\n",
      "[1020 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.models import Sequential, Model \n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "IMAGES_FOLDER = \"/kaggle/input/glaucoma-datasets/G1020/Images\"\n",
    "df = pd.read_csv(\"/kaggle/input/glaucoma-datasets/G1020/G1020.csv\")\n",
    "HEIGHT, WIDTH = 300, 300\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 150\n",
    "LR = 1e-4\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5f694f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T01:15:03.664480Z",
     "iopub.status.busy": "2025-04-02T01:15:03.664213Z",
     "iopub.status.idle": "2025-04-02T01:21:40.258951Z",
     "shell.execute_reply": "2025-04-02T01:21:40.258007Z"
    },
    "papermill": {
     "duration": 396.616824,
     "end_time": "2025-04-02T01:21:40.278924",
     "exception": false,
     "start_time": "2025-04-02T01:15:03.662100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in dataframe: 1020\n",
      "Dataset Shape: (1020, 300, 300, 3)\n",
      "Train Shape: (714, 300, 300, 3), Test Shape: (306, 300, 300, 3)\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.4616 - loss: 0.7710\n",
      "Epoch 1: val_accuracy improved from -inf to 0.29085, saving model to resnet50_model.keras\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 575ms/step - accuracy: 0.4661 - loss: 0.7685 - val_accuracy: 0.2908 - val_loss: 0.9709 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.6946 - loss: 0.6770\n",
      "Epoch 2: val_accuracy did not improve from 0.29085\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 295ms/step - accuracy: 0.6944 - loss: 0.6770 - val_accuracy: 0.2908 - val_loss: 1.0353 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.6917 - loss: 0.6384\n",
      "Epoch 3: val_accuracy did not improve from 0.29085\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 298ms/step - accuracy: 0.6915 - loss: 0.6386 - val_accuracy: 0.2908 - val_loss: 0.9496 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.7133 - loss: 0.6339\n",
      "Epoch 4: val_accuracy did not improve from 0.29085\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 304ms/step - accuracy: 0.7131 - loss: 0.6337 - val_accuracy: 0.2908 - val_loss: 0.8390 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.7118 - loss: 0.6148\n",
      "Epoch 5: val_accuracy did not improve from 0.29085\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 296ms/step - accuracy: 0.7114 - loss: 0.6152 - val_accuracy: 0.2908 - val_loss: 0.8164 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7050 - loss: 0.6418\n",
      "Epoch 6: val_accuracy improved from 0.29085 to 0.68627, saving model to resnet50_model.keras\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 329ms/step - accuracy: 0.7050 - loss: 0.6414 - val_accuracy: 0.6863 - val_loss: 0.6549 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.7221 - loss: 0.6198\n",
      "Epoch 7: val_accuracy did not improve from 0.68627\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 296ms/step - accuracy: 0.7217 - loss: 0.6200 - val_accuracy: 0.2908 - val_loss: 0.9323 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.6863 - loss: 0.6309\n",
      "Epoch 8: val_accuracy improved from 0.68627 to 0.70261, saving model to resnet50_model.keras\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 319ms/step - accuracy: 0.6871 - loss: 0.6309 - val_accuracy: 0.7026 - val_loss: 0.6130 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.7089 - loss: 0.6095\n",
      "Epoch 9: val_accuracy improved from 0.70261 to 0.70915, saving model to resnet50_model.keras\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 326ms/step - accuracy: 0.7088 - loss: 0.6096 - val_accuracy: 0.7092 - val_loss: 0.9175 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.6896 - loss: 0.6505\n",
      "Epoch 10: val_accuracy did not improve from 0.70915\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 293ms/step - accuracy: 0.6903 - loss: 0.6493 - val_accuracy: 0.2908 - val_loss: 1.6394 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.7030 - loss: 0.6181\n",
      "Epoch 11: val_accuracy did not improve from 0.70915\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 298ms/step - accuracy: 0.7030 - loss: 0.6184 - val_accuracy: 0.7092 - val_loss: 0.9711 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.6918 - loss: 0.6314\n",
      "Epoch 12: val_accuracy did not improve from 0.70915\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 300ms/step - accuracy: 0.6919 - loss: 0.6316 - val_accuracy: 0.7092 - val_loss: 2.2981 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.7006 - loss: 0.6340\n",
      "Epoch 13: val_accuracy did not improve from 0.70915\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 293ms/step - accuracy: 0.7004 - loss: 0.6341 - val_accuracy: 0.7092 - val_loss: 2.8173 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.6752 - loss: 0.6392\n",
      "Epoch 14: val_accuracy did not improve from 0.70915\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 299ms/step - accuracy: 0.6758 - loss: 0.6388 - val_accuracy: 0.7092 - val_loss: 2.4798 - learning_rate: 5.0000e-05\n",
      "Epoch 15/150\n",
      "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.7010 - loss: 0.6486\n",
      "Epoch 15: val_accuracy improved from 0.70915 to 0.71242, saving model to resnet50_model.keras\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 331ms/step - accuracy: 0.7006 - loss: 0.6484 - val_accuracy: 0.7124 - val_loss: 1.0662 - learning_rate: 5.0000e-05\n",
      "Epoch 16/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.7084 - loss: 0.6182\n",
      "Epoch 16: val_accuracy did not improve from 0.71242\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 297ms/step - accuracy: 0.7084 - loss: 0.6184 - val_accuracy: 0.2908 - val_loss: 4.6381 - learning_rate: 5.0000e-05\n",
      "Epoch 17/150\n",
      "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.6674 - loss: 0.6480\n",
      "Epoch 17: val_accuracy did not improve from 0.71242\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 293ms/step - accuracy: 0.6686 - loss: 0.6468 - val_accuracy: 0.2843 - val_loss: 1.0225 - learning_rate: 5.0000e-05\n",
      "Epoch 18/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.6977 - loss: 0.6281\n",
      "Epoch 18: val_accuracy did not improve from 0.71242\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 296ms/step - accuracy: 0.6980 - loss: 0.6280 - val_accuracy: 0.7026 - val_loss: 1.0704 - learning_rate: 5.0000e-05\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 403ms/step - accuracy: 0.2671 - loss: 1.2890\n",
      "Test Accuracy: 29.08%\n"
     ]
    }
   ],
   "source": [
    "def load_data(df, image_size=(HEIGHT, WIDTH)):\n",
    "    images, labels = [], []\n",
    "    print(f\"Total images in dataframe: {len(df)}\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img_name = row['imageID']\n",
    "        label = row['binaryLabels']\n",
    "        img_path = os.path.join(IMAGES_FOLDER, img_name)\n",
    "\n",
    "        if os.path.exists(img_path):\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_data(df)\n",
    "images = np.array(images) / 255.0\n",
    "labels = to_categorical(labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "print(f\"Dataset Shape: {images.shape}\")\n",
    "print(f\"Train Shape: {X_train.shape}, Test Shape: {X_test.shape}\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=90,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   brightness_range=[0.8, 1.2],\n",
    "                                   shear_range=0.2)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)  \n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=LR), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"resnet50_model.keras\", monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode=\"max\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\")\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "model.fit(train_generator, epochs=EPOCHS, validation_data=test_generator, callbacks=[checkpoint, reduce_lr, early_stop])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6209,
     "sourceId": 9900,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2296461,
     "sourceId": 3863247,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6989734,
     "sourceId": 11195803,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 415.969212,
   "end_time": "2025-04-02T01:21:43.078066",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-02T01:14:47.108854",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
